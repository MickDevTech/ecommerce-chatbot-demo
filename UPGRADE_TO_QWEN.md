# Upgrade a Qwen2.5-1.5B-Instruct

## ‚úÖ Modelo Actualizado

Se ha cambiado de **Mistral-7B** a **Qwen2.5-1.5B-Instruct**, un modelo mucho m√°s eficiente:

### Comparaci√≥n de Modelos

| Caracter√≠stica | TinyLlama-1.1B | Mistral-7B | **Qwen2.5-1.5B** |
|----------------|----------------|------------|------------------|
| **Par√°metros** | 1.1B | 7B | **1.5B** |
| **Razonamiento** | Limitado | Excelente | **Muy bueno** |
| **Coherencia** | Baja | Alta | **Alta** |
| **Seguimiento de instrucciones** | Regular | Excelente | **Excelente** |
| **Respuestas largas** | Dif√≠cil | Natural | **Natural** |
| **Velocidad (CPU)** | ~20-30 seg | ~40-60 seg | **~10-15 seg** ‚ö° |
| **RAM requerida** | ~2GB | ~14GB (7GB con 8-bit) | **~3-4GB** |
| **Espa√±ol** | Regular | Excelente | **Excelente** |

---

## üìù Paso 1: Actualizar `.env`

Abre tu archivo `.env` y cambia estas l√≠neas:

```bash
# CAMBIAR ESTAS L√çNEAS:
HF_MODEL_ID=Qwen/Qwen2.5-1.5B-Instruct
USE_LOCAL_MODEL=true
USE_8BIT_QUANTIZATION=false  # Qwen2.5-1.5B NO necesita cuantizaci√≥n
```

**Archivo completo `.env` deber√≠a verse as√≠:**

```bash
HF_TOKEN=tu_token_de_hugging_face
HF_MODEL_ID=Qwen/Qwen2.5-1.5B-Instruct
USE_LOCAL_MODEL=true
USE_8BIT_QUANTIZATION=false
ALLOWED_ORIGINS=http://localhost:5173,http://127.0.0.1:5173,http://localhost:3000,http://127.0.0.1:3000,*
VITE_API_URL=http://localhost:8000
```

---

## üöÄ Paso 2: Reiniciar el Backend

```bash
docker compose restart backend
```

**Primera carga:** El modelo se descargar√° (~3GB) y puede tardar 1-2 minutos.

---

## üéØ Mejoras Implementadas

### 1. **Prompts Optimizados para Qwen2.5**

Ahora usa el formato oficial de Qwen:
```
<|im_start|>system
Eres un asistente de ventas...
<|im_end|>
<|im_start|>user
Pregunta del cliente...
<|im_end|>
<|im_start|>assistant
```

### 2. **Par√°metros Ajustados**

```python
# Productos espec√≠ficos/detalles:
max_tokens = 350      # Qwen es eficiente
temperature = 0.6     # Balance creatividad/precisi√≥n

# Consultas generales:
max_tokens = 250      # Suficiente para listas
temperature = 0.7     # Natural pero controlado

# Otros:
repetition_penalty = 1.05  # Qwen maneja muy bien repeticiones
```

### 3. **Sin Cuantizaci√≥n Necesaria**

Qwen2.5-1.5B es lo suficientemente peque√±o para correr sin cuantizaci√≥n:
- **M√°s r√°pido** (sin overhead de cuantizaci√≥n)
- **Mejor calidad** (precisi√≥n completa)
- **Menos RAM** que Mistral-7B con cuantizaci√≥n

---

## üìä Ventajas de Qwen2.5-1.5B

### ‚úÖ Velocidad

| Modelo | Primera Carga | Respuesta |
|--------|---------------|-----------|
| TinyLlama-1.1B | ~30 seg | ~20-30 seg |
| Mistral-7B (8-bit) | ~2-3 min | ~40-60 seg |
| **Qwen2.5-1.5B** | **~1 min** | **~10-15 seg** ‚ö° |

### ‚úÖ Memoria

| Modelo | RAM Requerida |
|--------|---------------|
| TinyLlama-1.1B | ~2GB |
| Mistral-7B | ~14GB (7GB con 8-bit) |
| **Qwen2.5-1.5B** | **~3-4GB** |

### ‚úÖ Calidad

- **Excelente seguimiento de instrucciones**
- **Respuestas coherentes y naturales**
- **Muy bueno en espa√±ol**
- **Balance perfecto entre velocidad y calidad**

---

## üìñ Ejemplo de Respuesta

### Consulta: "Dame informaci√≥n sobre Laptop 14"

**Respuesta de Qwen2.5-1.5B:**
```
¬°Claro! Aqu√≠ est√° toda la informaci√≥n sobre la Laptop 14":

‚Ä¢ Laptop 14"

‚Ä¢ Precio: $799.99

‚Ä¢ Categor√≠a: electr√≥nica

‚Ä¢ Stock disponible: 8 unidades

‚Ä¢ Descripci√≥n: Port√°til 14 pulgadas, 16GB RAM, 512GB SSD.

¬øTe gustar√≠a saber algo m√°s sobre este producto?
```

---

## ‚ö†Ô∏è Consideraciones

### Requisitos de Hardware

- **RAM m√≠nima:** 4GB (recomendado: 8GB)
- **Espacio en disco:** ~3GB para el modelo
- **CPU:** Cualquier procesador moderno

### Tiempos de Respuesta

- **Primera consulta:** ~1 minuto (carga del modelo)
- **Consultas siguientes:** ~10-15 segundos
- **Con GPU:** ~2-3 segundos (si tienes NVIDIA GPU)

### Comparaci√≥n con Otros Modelos

**¬øPor qu√© Qwen2.5-1.5B y no otros?**

| Modelo | Ventaja | Desventaja |
|--------|---------|------------|
| TinyLlama-1.1B | Muy r√°pido | Calidad limitada |
| Mistral-7B | Mejor calidad | Muy lento en CPU |
| **Qwen2.5-1.5B** | **Balance perfecto** | - |
| Phi-3-mini | Similar a Qwen | Menos optimizado para espa√±ol |

---

## üß™ Pruebas Sugeridas

Despu√©s de reiniciar, prueba estas consultas:

1. **Producto espec√≠fico:**
   - "Dame informaci√≥n sobre Laptop 14"
   - "¬øQu√© stock hay de Auriculares Inal√°mbricos?"

2. **Categor√≠a:**
   - "¬øTienes camisetas?"
   - "Mu√©strame productos de electr√≥nica"

3. **Consulta compleja:**
   - "Recomi√©ndame algo para trabajar desde casa"
   - "¬øQu√© productos tienes entre $50 y $150?"

---

## üìà Monitoreo

Observa los logs para ver el progreso:

```bash
docker compose logs -f backend
```

Deber√≠as ver:
```
[INFO] cargando modelo Qwen2.5-1.5B-Instruct...
[INFO] detectado modelo causal (GPT/Llama), usando text-generation
[INFO] modelo causal cargado exitosamente en CPU
[INFO] generando respuesta con modelo Qwen2.5-1.5B-Instruct...
[INFO] respuesta del modelo: ¬°Claro! Aqu√≠ est√° toda la informaci√≥n...
```

---

## üêõ Troubleshooting

### Respuestas en ingl√©s
- Qwen2.5 maneja muy bien el espa√±ol
- Si persiste, verifica que el prompt incluya "Siempre respondes en espa√±ol"

### Modelo descarga lento
- Qwen2.5 es solo ~3GB (vs 14GB de Mistral)
- Deber√≠a descargar en 1-2 minutos con conexi√≥n normal

### Error de memoria
- Qwen2.5 solo necesita ~3-4GB de RAM
- Si tienes error, cierra otras aplicaciones

---

## ‚ú® Beneficios del Upgrade

1. ‚úÖ **3-4x m√°s r√°pido** que Mistral-7B
2. ‚úÖ **Usa 50% menos RAM** que Mistral-7B con cuantizaci√≥n
3. ‚úÖ **Mejor que TinyLlama** en calidad
4. ‚úÖ **Excelente en espa√±ol**
5. ‚úÖ **Balance perfecto** velocidad/calidad
6. ‚úÖ **No necesita cuantizaci√≥n**

---

¬°Disfruta de tu chatbot optimizado con Qwen2.5! üöÄ
